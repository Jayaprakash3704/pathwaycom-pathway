# OpenAI API Key (required for LLM-based reasoning)
OPENAI_API_KEY=your-openai-api-key-here

# Pipeline Configuration
LOGS_PER_SECOND=5.0
ERROR_SPIKE_PROB=0.15
ANOMALY_THRESHOLD=5
ERROR_RATE_THRESHOLD=0.3

# Agent Configuration
USE_LLM=true
DRY_RUN=false

# Output Configuration
OUTPUT_DIR=./output
LOG_LEVEL=INFO

# Demo Mode (set to true to run without full Pathway streaming)
DEMO_MODE=false
