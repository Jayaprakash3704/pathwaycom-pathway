# LLM API Configuration
# Option 1: OpenAI
OPENAI_API_KEY=your-openai-api-key-here
LLM_MODEL=gpt-4o-mini

# Option 2: Groq (faster, cheaper alternative)
# GROQ_API_KEY=your-groq-api-key-here
# LLM_BASE_URL=https://api.groq.com/openai/v1
# LLM_MODEL=llama-3.3-70b-versatile

# Pipeline Configuration
LOGS_PER_SECOND=5.0
ERROR_SPIKE_PROB=0.15
ANOMALY_THRESHOLD=5
ERROR_RATE_THRESHOLD=0.3

# Agent Configuration
USE_LLM=true
DRY_RUN=false

# Output Configuration
OUTPUT_DIR=./output
LOG_LEVEL=INFO

# Demo Mode (set to true to run without full Pathway streaming)
DEMO_MODE=false
